

				Storm

-Distributed fault-tolerant realtime computation system
-Easy to process unbounded streams of data 
-Different from traditional batch systems (store and process)

Stream
------
-Unbounded sequence of tuples 
-tuple: Core unit of data, is a named list of values 

Topologies
----------
-An application is defined in storm through a topology that describes its logic 
as a DAG of operators and streams
-Spouts: Source of data streams
-Bolts: Processes input streams and eventually produce output streams. They
represent the application logic 

Architecture
------------
-Two kinds of nodes 
-The master node runs a daemon called "Nimbus" to which topologies are submitted 
It is reponsible for scheduling, job orchestration and monitoring for failures
-Each Worker (slave) node runs a daemon called "Supervisor", that can run one or 
more worker process in which applications are executed 
-The coordination between these two entities is done through Zookeeper
-Mainly used to maintain state, because Nimbus and Supervisors are stateless

*Real time processing, spark is not becuase of micro-batching 
*Same worker node architecture deployed differently 

Entities
--------
-Worker process: one or more per cluster, each related to one topology - fault tolerant 
-Executor: Thread in the worker process, runs one or more tasks for the same component 
-Task: Component replica 

Trident API
-------
-High level abstraction on top of Storm
-Uses Spout and Bolt auto-generated by Trident before execution 
-Trident has functions, filters, joins, grouping, and aggregation
-Process streams as a series of batches 

*Built in garbage collection



