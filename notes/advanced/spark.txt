
--------------------------------------------------------------------------------------
                                    Spark
--------------------------------------------------------------------------------------
Spark: Big data engine
----------------------
  -Scheduling
  -Monitoring 
  -Distributed

Spark core
----------
Use memory and disk while its processing data.
  -Scala API
  -Python API
  -Java API
  -SparkR API
  -Dataframes API

Higher level libraries:
  -Spark SQL: Module for working with structured data
    -Dataframes
    -Hive queries will work with spark SQL
    -JDBC: Simba connector/driver
    -ODBC: Simba connector/driver

  -Spark Streaming: A way to analyse real time streams 
    -Flume:
    -Kafka:
  -MLib: Common algorithms for classification, regression, reduction, correlations
  -GraphX:

Resource manager
----------------
Coordinate running and execution of Spark:
  -Local mode
  -Yarn
  -Masos 
  -Standalone mode

File systems
------------
Hadoop: HDFS
Amazon: S3
RDBMS: SQL
NoSql: HBase, Cassandra

Distributions
-------------
-Cloudera
-Hortonworks

Why spark
---------
-To work with a unified engine
-Faster than MapReduce
  -In HDFS, chain mapReduce jobs, read results and run more chain mapReduce jobs.
  -Oozie: Run map reduce jobs in order
-Read data from HDFS, load it into memory and run the computations, keeping data in 
 memory in between the different transformations and write results to any source.
  -Leaverage memory: CPU read data from memory about 10GB/s

RDD
---
The main abstraction in Spark is that of a resilient distributed dataset(RDD), which 
represents a read-only collection of objects partitioned across a set of machines that
can be rebuilt if a partition is lost.
  
  -Users can explicitly cache an RDD in memory across machines and reuse it in multiple
   MapReduce like parallel operations.
  -RDDs achieve fault tolerance through a notion of lineage: If a partition of an RDD
   ist lost, the RDD has enough information about how it was derived from other RDDs to
   be able to rebuild just that partition.

Partitions
----------
RDD have many partitions, each partition requires a thread of computations, if you have
many cores, then the partitions of the RDD should be matched closely.

  -RDDs are distributed collections of elements
  -RDDs can be created in two ways, parallelize a collection and read data from 
   external source.
  -Base RDD, each unique block will feed one partitions of RDD, running transformation
   will have the same number of partitions, you can coalesce/repartition to fit the 
   amount of cores.
  -Collect action will ship all the data from the partitions inside that one jvm.

Transformations
---------------
Lazy, building a DAG, chain metadata of dependance from previous transformations.
Stage of execution, cash is also lazy, only when an action is called, the data will
be cashed. Most transformation are element wise, work one by one in each element in
the RDD, some work on a on-partition level and then iterate and close a connection.

Action
------
When you execute your DAG and all the information is processed and shiped over the 
network, if data is to big that can cause an out of memory error in the driver jvm.

Lifecycle of a spark program
----------------------------
1) Create some input RDDs from external data or parallelize a collection in your 
   driver program
2) Lazily transform them to define new RRDs using tranformations like filter, map
3) Ask Spark to cache any intermediate RDDs that will need to be reduced 
4) Launch actions such as count and collect to kick off a parallel computation, 
   which is then optimized and executed by Spark.

Types of RDDs
------------
HadoopRDD     DoubleRDD
FilteredRDD   JdbcRDD
MappedRDD     JsonRDD
PairRDD       SchemRDD
ShuffleRDD    VertexRDD
UnionRDD      EdgeRDD
PythonRDD

Interface RDDs
--------------
1) Set of partitions "splits"
2) List of dependencies on parent RDDs
3) Function to compute a partition given parents 
4) Optional preferred locations
5) Optional partitioning info -key

Example HadoopRDD
-----------------
partitions = one per HDFS block
Dependencies = none
Compute (partition) = read corresponding block

Example FilteredRDD
-------------------
Partitions = Same as parent RDD
Dependencies = one to one - direct dependency
Compute (partition) = compute parent and filter

Example JoinedRDD
-----------------
Partitions = One per reduce task
Dependencies = Shuffle on each parent 
Compute (partition) = read and join shuffled data
Partitioner = HashPartitioner (number of tasks)

Architecture Spark
------------------
-Static partitioning
  -Local
  -Standalone Scheduler
-Dynamic partitioning
  -Yarn
  -Mesos 

MapReduce Architecture
----------------------
Parallelism is achieved by having more process IDs and multiple JVMs, the map and 
reduce slots are hard-coded to be one or the other. When you start a new MapReduce
application, the mappers are started but during that time none of the reduce slots
are being used. 
Job tracker: brain
Name node:
Data node:
  -Task tracker: Map or reduce child jvm

Spark parallelism
-----------------
With different threads running inside the executor. Having one executor JVM on each
machine, inside that executor JVM there are slots where tasks can run. Generic slots
that can run map, reduce or transformation tasks.


Hadoop
------
-HDFS
-YARN
-MapReduce --> Spark

Spark local mode
----------------
Starting the scala shell will start the JVM, in the JVM the executor process and the driver process 
will run. In the JVM you can cache your RDDs, run your tasks (slots/cores). In general, you want to
subscribe to a core by a factor of 2 to 3.

Worker: The worker might exist but it is not used, the worker is not starting your local JVM, memory
        alocation. You dont need a worker in local mode.

Stand alone mode
----------------
Spark-env.sh: Spark local dirs, format each file in cluster to assign SSD/local disks, usefull when
an RDD is persisted with memory and disk and one of the partitions of the RDD has to be spilled down
to local disk --> it will go to disk  defined by local dirs. Memory and disk persist --> load in 
memory and then the leftover will go to disk.

Spark local dirs: also used for intermediate shuffle data, try to used SSD for faster processing

Start application: In standalone mode you cannot define the number of executors, but you can specify
                   how many cores you want. The Spark master is going to try to balance those cores 
                   across the cluster.

  -Spark.cores.max: The maximun amount of CPU cores to request for the application from across the 
                    cluster in total.
  -Spark.executor.memory: For the executors when they do start up, how much memory do you want each 
                          executor to have.

*The worker starts the executors.

Start
-----
When the machine is started, certain JVMs are instantiated with initiation scripts. Spark master
JVM will start up and on each local machine a worker JVM will start which will register with the 
Spark master. The master JVM and worker JVM are the resource managers.

When a job is submitted, a driver will start and that driver will contact the Spark Master. The spark
master is basically a scheduler to decide where its going to launch the executor JVMs and the master
will tell each worker to launch.

Spark master: Deciding and scheduling where each executor should run
  -If worker crashes, Spark master will re-start it 
Worker JVM: All their work is to start an executor JVM
  -If executor crashes, the worker will re-start it 

Executors JVMs: RDDs will be cached and where the tasks will run.

Multiple applications
---------------------
You can have one worker start multiple executors, however a worker is starting an executor for different
applications, one worker in standalone mode cannot start two executors for the same application.
Driver 1 --> 4 executors 
Driver 2 --> 4 executors 

Example
-------
250GB machine, for each JVM, you should not give a JVM more than 45GB of memory due to garbage collection 
pauses. How do you utilize all the memory in a single machine if you only want to run one driver and have
one application spark running.

  -If you want two different executors running for the same application on one machine, you will have to 
   have two workers, so each worker can launch an executor.
  -Spark_worker_instances: deafult 1, how many worker JVMs you want in each machine.
  -Spark_worker_cores: The number of cores to allow spark applications to use, default 1. Its not how many
   threads will run in the worker JVM, its how many cores can that worker give out to its underlying 
   executors.
  -Spark_worker_memory: How much memory can the worker give to its underlying JVM executors, total RAM - 1GB
  -Spark_daemon_memory: The memory to allocate to the actual spark master JVM and spark worker daemons 
                        default 512MB, the heap memory is set here.

Spark Master UI
---------------
If most of the memory is not being used when the worker JVM launch executors, settings needs to be changes to 
take most of the memory and cores used. Keep in mind that the driver, workers and master take some memory.

Memory: Its not the spark master JVM memory, its the total potential memory that this spark cluster has access
        to, meaning that this spark master has x amounts of workers jvms that are registered and that worker
        JVM can handout up to the y amount of memory to its underlying executors. If memory used is 0GB it 
        means that there is no Spark executors.

Spark Worker UI
---------------
You can see the executors that are running with how many cores and memory for each and their ID.
ID:
Cores:
Memory:

Spark UI
--------
Looking at the Spark Driver UI, the spark driver and the spark executors, exist in all the resource managers.
In local mode, the driver and the executor are in the same JVM. In standalone mode, YARN and masos you still
have a driver and executors, the difference is who starts the executor.

  -In standalone, its the worker JVM who starts the executor.

Jobs: A spark application is made of multiple jobs, the specific application can be the Spark shell, JAR -name.
      Every time an action is triggered, at the scala shell, that's going to kick off a job. A job is made of 
      multiple stages.

  -Active jobs
  -Completed jobs 

Stages: A job decomposes into one or more stages and a stage decomposes into one or more tasks.
  
  -Active stages
  -Completed stages

Storage: Shows RRDs that are cashed, persisted either in memory or in disk or in tachyon of heap. One way you 
         can figure out the number of partitions of an RDD is you can call the getNumPartitions of an RDD or 
         cache it.
  
  -If you read java strings out of HDFS file, when you cache the RDD of a 100MB file, in memory its going to
   take alot more memory due to the overhead of java serialization and deserialization costs.
  -You can check the RDD, find more information about how the RDD is persisted in memory, data distribution
   each partition and its size in memory.
  -If you RDD is loobsided, where most of the data is in a couple of partitions.

Environment: Variables and setting for the spark application, there are defaults settings, in the configuration
             files, when you submit a job, and in the spark source code on the spark context.

  -The highest precedence level that overrides everything else is in the source code in the spark context.
  -The next highest when you spark submit and you pass parameters there.
  -Spark env file.
  -Scala source code settings.

Executors: 
  -Thread dump: All of the threads for that executor, you can see the waiting state, running threads. It is 
                usefull to visualize the call stack of the executor and find which thread and what code is running
                at a specific moment in time. Helps to find hot spots or expensive sections. JStack to see what
                is going on.

Yarn Mode
---------
Yet another resource negiciator. 

Architecture
------------
The node managers are heart beating with the resource manager and sharing live resource information with the
resource manager. Such as my node has 7 cores of of 20 occupied, my node has 50% network bandwidth occupied.

  -Client: Submit application
  -Master machine: Running Resource manager
    -Resource manager: Global view of how many resources are being consumed and free across all the nodes. 
                       The task of the resource manager is to find a node manager with the free resource for
                       the application and start the application master through a container on a node.
                       -Scheduler: to decide where the applications masters will run and where the containers
                       will be scheduled.
                       -Applications master: If any application master crashes, the resource manager will 
                       restart the application master in the same node or in a different part of the cluster.

      -Application master: It does not perform any of the work, it works similar to a job scheduler, communicate
                           with the resource manager to get keys and tockens to start the containers by communicating
                           to other node managers nad launch the continer in them. The containers will report back
                           to the application master and the application master will report back to the client 
                           with reports and metrics.
                           While the resource manager is running, the application master can negociate resources
                           with the resource manager.
                           The application master can make really detailed requests in YARN, such as one container
                           with x CPUs, rack space, x amount of memory, etc.
  -Slave machine: Node manager

Two ways to run Spark in YARN
-----------------------------
The reason for applications masters in YARN is a way for containers to run executors, in YARN the executors in the 
containers are in direct communication with the driver/client.

-Client mode: The driver runs on the client itself, the client might be the computer/laptop, when you start the 
              scala shell you work with spark interactively.
              -When you call on an action on your RDD, the items inside the RDD will be shipped to the driver JVM
              over the network and get results back.
  -Application master
    -Containers
      -Executors: The executors for spark run within the containers

Node manager: starts the container and the executor within it, but it is the Application master that negociates
with the Resource Manager for resources such as containers 

Resource manager: Scheduling where the executors will run

* There's another scheduler in Spark inside the driver, that is the scheduler that will decide where the actual 
tasks will be scheduled within the executors. when you have many executors, you want to place the task in the 
executor where the partition the executor is going to work on is cached. Data locality.
*The executor starts only after the driver starts which is where the spark context is created.=
*When you submit and application, you need the driver connected for the jobs to run.

-Cluster mode: The client submits the application including the driver, the jar file or python script and then the
               driver will run within the YARN application master itself. With the results saving it to HDFS, no 
               interactivity.

  -YARN settings: Set for each application/driver
    --num-executors: Controls how many executors will be allocated
    --executor-memory: RAM for each executor
    --executor-cores: CPU cores for each executor

Dynamic allocation: Ability to increase and decrease the number of executors live in an applications, when it is
                    enabled, you need to configure the minumum and maximum executors. When it hits the timeout
                    it will check for a backlog of tasks built in the driver that have not been executed then it
                    will increase the amount of number of executors, when it hits the scheduler timeout it will 
                    exponentially increase executors every 30 seconds until it hits max. If any of the executors
                    are not being scheduled for the k period, it will terminate the executors until it reaches the
                    minimum amount of executors.

  -spark.dynamicAllocation.enabled --> true
  -spark.dynamicAllocation.minExecutors
  -spark.dynamicAllocation.maxExecutors
  -spark.dynamicAllocation.sustainedSchedulerBackLogTimeout (N)
  -spark.dynamicAllocation.schedulerBacklogTimeout (M)
  -spark.dynamicAllocation.executorIdleTimeout (k)

YARN Resource manager UI
------------------------
Spark history server, by default JVM running with 0.5GB. Once the spark application terminates, the driver also
terminates so you cant see any metrics. Using the history server allows you to check past jobs.

*Tasks always runs on executors.
*Who starts the executors changes depending on the resource manager. Such as humans, worker JVM, Node Manager or
 Mesos slave.
*The spark central master, decides where the executors will run. Such as standalone master, YARN app master or 
 Mesos master.
*Spark submit, lets you submit a Spark application across multiple cluster managers. So you can develop an 
 application in local mode in your laptop, then keep the code the same and specify which resource manager to use.
  -spark://host:port --> Standalone master 
  -mesos://host:port --> Mesos cluster
  -YARN --> YARN cluster, need to export HADOOP_CONF_DIR to point location of Hadoop configuration directory
  -Local[N] --> Run in local mode and use N cores

Recommended settings
--------------------
-Use at mostly only 75% of a machine's memory for Spark
-Minimum Executor heap size should be 8GB
-Max Executor heap size depends, 40GB --> GC  
-Memory usage is greatly affected by storage level and serialization format

Memory
------
When you persist an RDD to memory, you can persist it to memory or memory and disk. Per executor basis

cache: stores the RDD deserialized as java objects inside the JVM, if certain partition of the RDD dont fit in 
       memory then those partitions wont be cached, they will be droped. The partitions droped from the RDD will
       be recomputed on the fly, from the underlying data source or earlier RDD.

RDD.cache() == RDD.persist(MEMORY_ONLY)
RDD.persist(MEMORY_ONLY_SER)
RDD.persist(MEMORY_AND_DISK)
RDD.persist(MEMORY_AND_DISK_SER)
RDD.persist(MEMORY_ONLY_2)
RDD.unpersist()

serialized cache: Also persist to memory serialized Java objects, on Byte array per partition. Generally more space
efficient, try to use a fast deserialization library, by deafult Java deserialization. It will slow down the 
process from a compute perspective.
  -Reduce the cost of garbage collection, because many individual records can be stored as a single serialized 
   buffer.

Memory and disk: It will try to store the RDD partitions in deserialized form as Java objects in the JVM memory,
                 if they dont fit, they will be stored on disk instead. What moves is the entire partition. 
                 Deserialized in memory and serialized in disk. It's always serialized when it spills.

Memory and disk serialized: It will be serialized in memory and disk.

*If RDD is extremely costly to recreate, and if you lose one partition due to a wide dependency in a large RDD,
 in general you dont want MEMORY_ONLY_2.
*If RDD fits in memory, chose MEMORY_ONLY
*If not, use MEMORY_ONLY_SER with fast serialization library
*Don't spill to disk unless functions that computed the datasets are very expensive, recomputing might be as fast
 as reading from disk.
*Use replicated storage levels sparingly and only if you want fast fault recovery.
*Intermediate data is automatically persisted during shuffle operations

Tackyon: Off heap storage, the RDD will be stored in a serialized format in Tackyon, which will reduce the garbage
         collection overhead inside the executor JVMs. The RDD can continue to live on Tackyon if executor crashses

Memory allocation
-----------------
Spark uses memory for:
  -RDD storage: When you can .persist() or .cache(). Spark will limit the amount of memory used when caching to a 
                certain fraction of the JVM's 
  -Shuffle and aggreggations buffers: When performing shuffle operations, Spark will create intermediate buffers 
                for storing shuffle output data. These buffers are used to store intermediate results of 
                aggregations in addition to buffering data that is going to be directly output as part of the 
                shuffle.
  -User code: Spark executes arbitrary user code, so user functions can themselves require substantial memory.
                For instance, is user application allocates large arrays or objects, these will content for overall
                memory usage. User code has access to everything left in the JVM heap after the space for RDD storage
                and shuffle storage are allocated.

Executor JVM:
  -60% for Cached RRDs.
  -20% for shuffle memory, for the map side and reduce side aggregations.
  -20% will be used for the user programs, threads.

Data serialization
------------------
Serialization is used when:
  -Transferring data over the network
  -Spilling data to disk
  -Caching/persisting to memory serialized
  -Broadcasting variables

Java:
  -Uses ObjectOutputStream framework
  -Works with any class you create that implements java.io.Serializable
  -You can control the performance of serialization more closely by extending java.io.Externalizable 
  -Flexible but slow
  -Leads to large serialized formats for many classes

Kryo:
  -Recommended serialization for production apps
  -Use Kryo version 2 for speedy serialization (10x) and more compactness
  -Does not support all Serializable types
  -Requires you to register the classes you'll use in advance 
  -If set, will be used for serializing shuffle data between nodes and also serializing RDDs to disk

PySpark: Stored objects will always be serialized with Pickle library, so it does not matter whether you choose a 
serialized level

*Spark context: conf.set("spark.serializer","org.apache.spark.serializer.KryoSerializer")
*Register classes with Kryo: conf.registerKryoClasses(Seq(classOf[MyClass],...)
  -If your objects are large, you may need to increase spark.Kryoserializer.buffer.mb config property
  -The default is 2, but this value needs to be large enough to hold the largest object you will serialize

Determining memory consumption
------------------------------
Spark context logs on the driver program or Spark UI. Logs will tell you how much memory each partition is consuming,
which you can aggregate to get the total size of the RDD.

INFO BlockManagerMasterActor: ADded rdd_0_1 in memory on mbk.local:50311 (size: 7171.5 KB, free: 332.3 MB)

Tuning for Spark
----------------
High churn: When you are caching everything, which will be triggering garbage collection, the JVM is having to 
            evict all objects to make space for the new ones. The cost of garbage collection is proportional to
            the number of Java objects. Not the size of a specific object, so use an array of ints instead of a 
            linked list.
Low churn: 

*Meassure GC: -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps

Gargabe Collection
------------------
Parallel GC: -XX:+UseParallelGC or -XX:ParallelGCThreads=<#>
  -Uses multiple threads to do young gen GC
  -Will default to Serial on single core machines
  -Aka "throughput collector"
  -Good when a lot of work is needed and long pauses are acceptable
  -Use case, batch processing
Parallel Old GC: -XX:+UseParallelOldGC
  -Uses multiple threads to do both young gen and old gen GC
  -Also a multithreading compacting collector
  -Hotspot does compaction only in old gen
CMS GC: -XX:+UseConcMarkSweepGC or -XX:ParallelCMSThreads=<#>
  -Concurrent Mark sweep aka "Concurrent low pause collector"
  -Tries to minimize pauses due to GC by doing most of the work concurrently with application threads
  -Uses same algorithm on young gen as parallel collector
  -Use case, streaming
G1 GC: -XX:+UseG1GC
  -Garbage first is available starting Java7
  -Designed to be long term replacement for CMS
  -Is a parallel, concurrent and incrementally compacting low-pause GC




